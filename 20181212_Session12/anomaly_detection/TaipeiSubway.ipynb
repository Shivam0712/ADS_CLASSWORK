{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sbn\n",
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "import datetime\n",
    "from sklearn.mixture import GaussianMixture "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "****** PREPROCESSING NETWORK DATA ********"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#read the data\n",
    "workfolder='data/';\n",
    "TNet=pd.read_csv(workfolder+'taipeiD_TNet2.csv',header=-1);\n",
    "TNet.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#split into train and test\n",
    "X=np.array(TNet);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check X \n",
    "print(X.shape)\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# minmax scaling of every column\n",
    "for i in range(X.shape[1]):\n",
    "    X[:,i]=(X[:,i]-X[:,i].min())/(X[:,i].max()-X[:,i].min())\n",
    "# check x\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to save\n",
    "def save(filename,X):\n",
    "    outfile = open(filename,'wb')\n",
    "    pickle.dump(X,outfile)\n",
    "    outfile.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to load\n",
    "def load(filename):\n",
    "    infile = open(filename,'rb')\n",
    "    X=pickle.load(infile, encoding='latin1')\n",
    "    infile.close()\n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save taipei data\n",
    "save('TaipeiExchange1.pkl',X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#XS=np.argsort(X,axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from sklearn import preprocessing\n",
    "scaler = preprocessing.StandardScaler().fit(X)\n",
    "X=scaler.transform(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***** EVENTS DATA *******"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import events data\n",
    "events=pd.read_csv(workfolder+'Holidays.csv', encoding = \"ISO-8859-1\", parse_dates=['Date'], infer_datetime_format=True);\n",
    "\n",
    "# Check events data\n",
    "print(events.shape)\n",
    "print(events.info())\n",
    "events.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Subset events\n",
    "events=events.loc[events.Date<datetime.datetime(2018,10,31)]\n",
    "\n",
    "# Check events data\n",
    "print(events.shape)\n",
    "print(events.info())\n",
    "events.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Event day number from 1-jan-2017\n",
    "events['Day']=(events.Date-datetime.datetime(2017,1,1)).dt.days\n",
    "# Check events\n",
    "events.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of 'Day' for national holidays\n",
    "holidays=events.Day[events['Holiday Type']=='National holiday']\n",
    "# check holidays\n",
    "print(len(holidays))\n",
    "holidays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of 'Day' for national holidays\n",
    "otherevents=events.Day[events['Holiday Type']!='National holiday']\n",
    "# check otherevents\n",
    "print(len(otherevents))\n",
    "otherevents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "******* READ THE TRANSFORMED NETWORK DATA IN REPRESENTATION FEATURE SPACE ********"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load the coded data\n",
    "y=load('Tapeiexchange2.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#try PCA as an alternative\n",
    "from sklearn import preprocessing\n",
    "from sklearn.decomposition import PCA\n",
    "Xs=preprocessing.StandardScaler().fit_transform(X)\n",
    "#y=preprocessing.StandardScaler().fit_transform(y)\n",
    "pca = PCA(11) \n",
    "y = pca.fit_transform(Xs)\n",
    "#y = pca.fit_transform(y)\n",
    "#y=preprocessing.StandardScaler().fit_transform(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#the data appers to show some clustering. Why do you think is that?\n",
    "plt.scatter(y[:,3],y[:,4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#see how holidays appear in this new feature space\n",
    "plt.figure()\n",
    "features=[3,4]\n",
    "plt.scatter(y[:,features[0]],y[:,features[1]])\n",
    "plt.scatter(y[holidays,features[0]],y[holidays,features[1]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clearly holidays demonstrate some patter, but holiday recognition might need to be done in each cluster separately. So we'll cluster the data first"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pval=0.2 #sensitivity of anomaly detection; percentage of the most anomalous days to take"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def anomalyOutput(array, arrColumns):\n",
    "    iterN=20\n",
    "    rind=array[:,0]>-10 #index of regular (non-outlier pods/ints)\n",
    "    for i in range(iterN): #iterate\n",
    "        print('Iteration {}'.format(i+1))\n",
    "        gm=GaussianMixture(n_components=3,n_init=100,max_iter=1000,random_state=0) #clustering model\n",
    "        clustering=gm.fit(array[rind,arrColumns]) #fit EM clustering model excluding outliers\n",
    "        l=clustering.score_samples(array) #estimate likelihood for each point\n",
    "        Lthres=sorted(l)[int(len(l)*pval)] #anomaly threshold\n",
    "        rind0=0+rind\n",
    "        rind=l>Lthres #non-anomalous points\n",
    "        if all(rind==rind0):\n",
    "            print('Convergence in {} iterations'.format(i+1))\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "anomalyOutput(X_pca, 0:2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Anomaly frequency among holidays={0:.2f}%'.format(100.0*sum(l[holidays]<=Lthres)/len(holidays)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print('Anomaly frequency among observances={0:.2f}%'.format(100.0*sum(l[otherevents]<=Lthres)/len(otherevents)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Anomaly frequency among other days={0:.2f}%'.format(100.0*(sum(l<Lthres)-sum(l[holidays]<=Lthres))/(len(l)-len(holidays))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ADS",
   "language": "python",
   "name": "ads"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
